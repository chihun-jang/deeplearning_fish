합성곱 신경망 (CNN)

CNN은 이미지 인식과 음성인식등 다양한 곳에서 사용되고있고,
특히 이미지 인식 딥러닝의 기초가 된다.

### 7.1 전체구조

합성곱 계층과(convolutional layer) 풀링 계층(pooling layer)이 등장한다.

지금까지의 신경망은 인접 계층의 모든 뉴런과 결합되어있었고, 이를 완전연결(fully-connected/ 전결합)이라고 한다.
완전히 연결된 계층을 Affine 계층이라는 이름으로 구현했다.

> 합성곱 : 두 함수중 하나를 reverse or shift 시시켜가면서 나머지 함수와의 곱을 연이어 적분한다.

Affine와 CNN의 차이

- Affine : input -> Affine-ReLU -> Affine-ReLU -> Affine-Softmax
- CNN : input -> Conv- ReLU-Polling -> Conv-ReLU-Polling-> Conv-ReLU -> Affine-ReLU -> Affine-Softmax
  d
  이처럼 CNN계층에서 Pooling 은 생략되기도 한다.

### 합성곱 계층

CNN에서는 패딩(Padding), 스트라이드(Stride)와 같은 CNN고유의 용어가 등장한다.또한 각 계층사이에는 입체적인 data가 흐른다.

- 완전연결 계층의 문제점
  지금까지 본 완전연결 신경망에서는 완전연결계층(affine 계층)을 사용했다.
  이에서는 인접하는 계층의 뉴런이 모두 연결되고 출력의 수는 임의로 정할수 있다.

이때의 문제점은 data형상이 무시된다는 것이다.

ex) img 의 경우 가로,세로,깊이(색상)으로 구성된 3차원 data인데 affine에 입력할때는 1차원으로 flatten해줘야한다. 지금까지는 MNIST를 1x28x28의 이미지를 1x784로 평탄화 해서 Affine계층에 입력한다.
따라서 이런경우 3차원속에서 가까운 픽셀끼리 상관관계나 어떠한 규칙성이라는게 있을수 있는데 1차원으로 입력이 들어가게되면 그러한 정보들은 살릴수가 없다.

반면 합성곱 계층은 이러한 형상을 유지한채 처리하고 전달해주기 때문에 제대로 이해할 가능성이 있다.

CNN에서는 합성곱 계층의 입출력 데이터를 feature map이라고 하는데 합성곱 계층의 입력 data를 input feature map , 출력데이터를 output feature map 이라고 한다.

- 합성곱 연산
  img 처리에서 말하는 filter 연산을 말한다.
  즉 합성곱 연산은 입력 데이터와 필터(커널) 그리고 출력이 있는데

연산 방법은
필터의 window를 일정 간격 이동해가면서 input data에 적용해주는것인다.
이때 필터에 대응하는 연산을 처리해준다.(단일 곱셈 누산 Fused Multiply Add/ FMA, 대응하는 원소끼리 곱한후 총합을 구하는것,)

> scipy에서 2차원 합성곱함수로 예를 따라해보면 다른 결과가 나오는데
> 그이유는 scipy에서는 교차상관으로 해야하기때문이다. 교차상관은 FMA에서 filter를 flipping 해준 것이고 이때의 플리핑이란 좌우 상하 한번씩 뒤집는 것을 말한다.(deep learning에서는 따로 구분하지 않는다.)

CNN에서는 필터의 매개변수가 그동안의 가중치와 같은 역할을 하고,
편향의 경우에는 필터를 적용한 후 data에 더해진다.(항상 1개만 존재한다.)

### 패딩

합성곱 연산을 수행하기전에 input data주변을 0으로 채우기도 한다.
패딩은 주로 출력 크기를 조절할 목적으로 사용하는데,
왜냐하면 합성곱연산을 되풀이하는 심층 신경망에서는 출력이 작아지면 입력도 작아지므로 문제가 될수있기 때문이다.(어느순간 1).따라서 패딩을 줌으로써 입력크기 그대로 다음 층에 넘겨줄수 있다.

### 스트라이드

필터를 적용하는 위치간격을 스트라이드라고 한다.
(==>윈도우가 이동하는 간격을 조정한다)(따라서 당연한 말이지만 스트라이드 크기를 키우면 출력 크기가 줄어든다)

### 패딩과 스트라이드 출력크기 계산

입력크기를(H,W),필터 크기를 (FH, FW), 출력크기를 (OH,OW), 패딩을 P , 스트라이드 S

OH = (H + 2P -FH)/s + 1

OW = (W + 2P - FW)/S + 1

문자로 나타내보면
출력 = (입력 + 2x패팅 - 필터) /스트라이드 + 1

이때 Output이 정수로 나와야하는데
딥러닝 프레임워크중에는 정수가 안나오면 가까운 정수로 반올림하는 방법을 사용해주는 애도 있다.

### 3차원에 적용시켜보기

만약 깊이라는 차원이 추가 되었다면 가로 세로에 대해서 합성곱 연산을 먼저 수행하고 그 결과를 더해서 출력을 얻으면 된다.

이때의 주의사항으로는 input의 channel수와 필터의 채널수가 같아야 한다는 것
(그리고 각 채널들이 모두 같은 크기여야한다 )

3차원 데이터를 다차원 배열로 나타낼때는(C,H,W) (순서대로 채널, 높이, 너비다)
필더도 이와 같이 (C,FH,FW)로 쓴다.

필터를 그냥 1개의 필터(여기서 필터 1개라 하면 정육면체 모양의 깊이가 있는 필터이지만 채널의 계산 결과를 합쳐서 1개의 값으로 변환하기때문에 출력값은 깊이가 1인 output이 나오게 된다. 따라서 다음으로 전해주기위해서 출력도 여러개로 하고싶으면 필터를 뵥수개 적용시켜 주면 된다.)

(C, H , W ) ⨀ (FN, C, FH , FW) --> (FN, OH,OW) + (FN,1,1) --> (FN,OH,OW)

이렇게 연산에서 필터의 수도 고려해줘야하는데, 따라서 필터의 가중치 data는 4차원의 모양으로 작성해준다 (출력갯수, 입력채널수, 높이, 너비)

### 배치처리

합성곱 연산도 배치처리를 지원한다.
따라서 각 계층의 차원을 늘려서 4차원으로 저장하는데
(data수, 채널수, 높이, 너비) 순서로 저장하낟.

(N,C, H , W ) ⨀ (FN, C, FH , FW) --> (N,FN, OH,OW) + (FN,1,1) --> (N,FN,OH,OW)

이 흐름은 한번 흘러갈때마다 data N개에 대한 합성곱 연산이 이뤄진다는것이 합성곱 배치처리의 주요포인트다.

### 풀링계층

풀링은 가로 세로 방향의 공간을 줄이는 연산이다.
풀어서 작성해보면 풀링이란 filter의 윈도우로 대상영역(2x2 필터의 영역과 비슷)에서 특정 규칙을 기준으로 값을 뽑아내 data 공간을 줄이는 것이다.
이때 대상영역(window)의 크기와 스트라이드(이동간격)은 같은 값으로 설정하는게 보통이다.

> 풀링의 종류에는 최대 풀링 외에도 평균풀링 등이 있다.(이미지 분야에서는 최대풀링을 사용한다.)

#### 풀링계층의 특징

- 학습해야할 매개변수가 없다.==> 대상영역에서 특정 처리를 하는것이므로 학습할것이 없다.
- 채널 수가 변하지 않는다 ==> 입력채널수 그대로 출력 데이터로 보낸다(독립적으로 계산된다.)
- 입력의 변화에 영향을 적게 받는다(입력data가 조금 변해도 풀링의 결과는 같게 나올수 잇따는 말이다.)

### 합성곱/ 풀링계층 구현하기

4차원 배열

```python
x = np.random.rand(10,1,28,28)
x.shape  # (10,1,28,28)

x[0].shape #(1,28,28)
```

> im2col로 데이터 전개하기
> 원래 합성곱 연산을 그대로 구현하려면 for문을 써야하겠지만 그렇게 되면 복잡+ 성능저하가 생긴다. 따라서 im2col함수를 이용해서 간단하게 구현해보자

im2col : input data를 필터리하기 좋게 전개하는 함수이다.
(구체적으로는 필터를 적용하는 영역을 한 row로 변환해서 전개한다.)
대신 스트라이드에 따라서 필터링시 겹치는 영역이 생길수있는데 그렇게 되면 im2col로 전개할때 row의 갯수가 많아지게 되고 이는 memory를 많이 소비하는 단점이있다.
하지만 그러한 단점에도 불구하고 컴퓨터는 행렬의 계산에 특화되어있으므로 문제를 행렬로 단순화 시키면 효율을 높일수 있다.

즉 이 말처럼 im2col은 image to column의 줄임말이다.

input data를 행렬로 바꿔 주었으니
여러장의 filter 또한 행렬의 column으로 바꿔서 행렬의 곱을 수행해주자
그리고 이러한 행렬의 곱 이후에는 출력 data가 2차원이므로 reshape를 통해서 다시 4차원으로 변형해줘야한다.

im2col 을 이용해서 구현하면 손쉽게 전개하여 연산해줄수있는데
이를 통해 Affine계층과 거의 유사한 프로세스로 구현할숭 있다.

단 주의할것은 im2col을 이용한 함수의 역전파는 col2im을 사용하면 되는데
이 부분만 제외하면 Affine계층과 똑같다.

### 풀링계층 구현하기

풀링계층또한 im2col을 사용해서 data를 전개하는데 대신 이때 채널이 독립적으로 보전이 되기때문에 약간의 차이가 잇다.

이채널의 구분은 그냥 1~4row까지는 채널 1, 이런식으로 구분해주면 된다
그리고 각 row에서 최댓값을 뽑아내서 순서대로 2x2에다가 넣어주고
data의 갯수는 유지해준다

풀링계층의 구현 단계

1. 입력 데이터를 전개한다
2. 행별 최댓값을 구한다
3. 적절한 모양으로 성형한다.

이때 최댓값은 np.max를 사용해서 구현할수있는데 추가로 축 axis를 지정하면 축마다 최댓값을 구할수있따.

이처럼 합성곱 계층과 풀링계층은 img인식에 필수적인 모듈이다.
왜냐면 공간적인 형상을 학습에 반영해서 할수있으므로 CNN이 손글씨 숫자인식을 하기 수월해지는 것이다.

## CNN시각화 하기

학습이 된 규칙성있는 필터는 무엇을 보는 걸까?
Edgs(색상이 변하는 경계선)와 Blob(국소적으로 덩어리진 영역)등을 보고있다.
이러한 정보들이 뒤로 전달되는게 CNN에서 일어나고 있는 일들이다.

층이 깊어진다면
첫번째 층에서 edge와 blob 3번째 층에서 texture, 5번째 층에서 object part
마지막 층에서 object class이런식으로 뉴런이 반응한다.
즉 여러겹 쌓아 나가면 층이 깊어질수록 복잡하고 추상화된 정보를 추출할수있다.

### 대표적인 CNN

- LeNet
  합성곱 계층과 서브샘플링 계층을 반복하고 완전연결 계층을 거치면서 출력하는데
  활성화 함수를 sigmoid로 사용하고 서브샘플링을 통해 중간 data의크기를 줄이는데 현재의 CNN과 차이가 있다.
- AlexNet
  합성곱 계층과 풀링계층을 거치고 마지막으로 완전 연결 계층을 거쳐 결과를 출력하는데
  활성화 함수로 ReLU를 이용한다.
  LRN(Local Response Normalization)이라는 국소적 정규화를 실시하는 계층 이용
  Dropout을 이용한다

뿐만아니라 병렬계산에 특화된 GPU가 보급되고
빅데이터를 통해서 매개변수 pitting등 의 해결책 제시 덕분에 보다 진보된 성능을 보이고있다.
